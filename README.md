# End-to-End ML Pipeline: Tabular Data Classification with Explainability

This project implements a complete machine learning pipeline for classifying structured/tabular data. It includes data cleaning, feature selection, model building, evaluation, and model interpretability using LIME and SHAP. The goal is to demonstrate best practices for building explainable and production-ready ML models.

## ğŸ“Œ Key Features
- ğŸ“Š **EDA & Preprocessing**: Handles missing values, encodes categorical data, and scales features.
- ğŸ§  **Feature Selection**: Uses correlation and mutual information to identify key predictors.
- âš™ï¸ **Modeling & Tuning**: Trains multiple models (Random Forest, SVM, Logistic Regression) with cross-validation and hyperparameter tuning via GridSearchCV.
- ğŸ” **Explainability**: Applies LIME and SHAP for interpreting predictions and feature impact.
- ğŸ§± **Modular Design**: Built using clean functions and Scikit-learn Pipelines for reusability.


## ğŸš€ Technologies Used
- Python, Pandas, Scikit-learn, Matplotlib, Seaborn, LIME, SHAP

## ğŸ“ˆ Results
- Achieved an F1-score of ~89% using Random Forest with tuned parameters
- LIME and SHAP visualizations provided clear explanations of individual predictions and global feature importance

## ğŸ§© Future Improvements
- Streamlit/Gradio UI for live demo
- Deployment as a REST API
- Experimenting with AutoML or deep learning models

---

## ğŸ“„ Project Summary

```text
â€¢ Built a complete ML pipeline for tabular data classification with preprocessing, feature selection, and model evaluation.  
â€¢ Achieved 89% F1-score using cross-validated Random Forest with hyperparameter tuning and Scikit-learn Pipelines.  
â€¢ Used LIME and SHAP to explain individual predictions and global feature importances for model transparency.
